# Model Catalog - 13+ AI Models

## Overview

The platform integrates **13+ OpenAI models** across four families, each optimized for different use cases and cost profiles.

## Model Families

### 1. GPT-4 Family - Reliable Workhorses

**Models**: GPT-4o, GPT-4o-mini, GPT-4.1

**Characteristics**:
- Vision-capable (analyze images)
- Fast response times
- Multi-turn conversation support
- Cost-effective (especially GPT-4o-mini)

#### GPT-4o-mini
**Best for**: High-volume, cost-sensitive applications

| Property | Value |
|----------|-------|
| **Pricing** | $0.15 input / $0.60 output per 1M tokens |
| **Vision** | ✅ Supported |
| **Max Tokens** | 2,048 (auto) → 4,096 (pro) |
| **Temperature Range** | 0.4 (instant) → 0.7 (auto) |
| **API** | Chat Completions |

**Use Cases**:
- Simple Q&A
- Draft generation
- Summarization
- Daily student queries

#### GPT-4o
**Best for**: High-intelligence tasks requiring accuracy

| Property | Value |
|----------|-------|
| **Pricing** | $2.50 input / $10.00 output per 1M tokens |
| **Vision** | ✅ Supported |
| **Max Tokens** | 2,048 (instant) → 6,144 (pro) |
| **Temperature Range** | 0.35 (instant) → 0.65 (auto) |
| **API** | Chat Completions |

**Use Cases**:
- Complex analysis
- Multi-step reasoning
- Image understanding
- Research assistance

#### GPT-4.1
**Best for**: Enhanced reasoning with vision

| Property | Value |
|----------|-------|
| **Pricing** | $2.50 input / $10.00 output per 1M tokens |
| **Vision** | ✅ Supported |
| **Max Tokens** | 2,048 (instant) → 8,192 (pro) |
| **Temperature Range** | 0.35 (instant) → 0.6 (auto) |
| **API** | Chat Completions |

**Use Cases**:
- Advanced problem-solving
- Document analysis with images
- Technical explanations

---

### 2. o-Series - Reasoning Specialists

**Models**: o1-mini, o1-preview, o3, o3-mini

**Characteristics**:
- Dedicated reasoning capability
- Configurable reasoning effort (low/medium/high)
- No temperature control (reasoning-optimized)
- Higher cost, higher quality

#### o1-mini
**Best for**: Efficient reasoning tasks

| Property | Value |
|----------|-------|
| **Pricing** | $3.00 input / $12.00 output + $12.00 reasoning per 1M tokens |
| **Vision** | ✅ Supported |
| **Max Tokens** | 1,024 (instant) → 4,096 (pro) |
| **Reasoning Effort** | low → high |
| **API** | Chat Completions |

**Use Cases**:
- Logic problems
- Math and coding challenges
- Step-by-step analysis

#### o1-preview
**Best for**: Advanced reasoning preview

| Property | Value |
|----------|-------|
| **Pricing** | $15.00 input / $60.00 output + $60.00 reasoning per 1M tokens |
| **Vision** | ✅ Supported |
| **Max Tokens** | 2,048 (instant) → 8,192 (pro) |
| **Reasoning Effort** | low → high |
| **API** | Chat Completions |

**Use Cases**:
- Research-grade analysis
- Complex simulations
- Multi-variable problem-solving

#### o3
**Best for**: Production reasoning (latest generation)

| Property | Value |
|----------|-------|
| **Pricing** | $20.00 input / $80.00 output + $80.00 reasoning per 1M tokens |
| **Vision** | ✅ Supported |
| **Max Tokens** | 2,048 (instant) → 8,192 (pro) |
| **Reasoning Effort** | low → high |
| **API** | Chat Completions |

**Use Cases**:
- Cutting-edge reasoning tasks
- Scientific problem-solving
- Advanced algorithmic challenges

#### o3-mini
**Best for**: Cost-effective o3 performance

| Property | Value |
|----------|-------|
| **Pricing** | $3.50 input / $14.00 output + $14.00 reasoning per 1M tokens |
| **Vision** | ✅ Supported |
| **Max Tokens** | 1,536 (instant) → 5,120 (pro) |
| **Reasoning Effort** | low → high |
| **API** | Chat Completions |

**Use Cases**:
- Budget-conscious reasoning
- Moderate complexity problems
- Daily technical queries

---

### 3. GPT-5 Flagship - Next Generation

**Models**: GPT-5, GPT-5-mini, GPT-5-nano

**Characteristics**:
- **Latest generation** (requires government ID verification)
- Verbosity control (low/medium/high)
- Reasoning effort tuning (minimal/low/medium/high)
- Highest token limits (up to 128k output)
- Uses newer **Responses API**

#### GPT-5
**Best for**: Flagship performance

| Property | Value |
|----------|-------|
| **Pricing** | $1.25 input / $10.00 output + $10.00 reasoning per 1M tokens |
| **Vision** | ✅ Supported |
| **Max Tokens** | 16,384 (instant) → 128,000 (pro) |
| **Reasoning Effort** | minimal → high |
| **Verbosity** | low / medium / high |
| **API** | **Responses API** |

**Special Features**:
- Non-streaming fallback when organization not verified
- Supports mode picker (auto/instant/thinking/pro)
- Advanced verbosity control for output detail level

**Use Cases**:
- Research papers
- Comprehensive analysis
- Long-form content generation
- Complex multi-step tasks

#### GPT-5-mini
**Best for**: Cost-efficient GPT-5 access

| Property | Value |
|----------|-------|
| **Pricing** | $0.25 input / $2.00 output + $2.00 reasoning per 1M tokens |
| **Vision** | ✅ Supported |
| **Max Tokens** | 16,384 (instant) → 128,000 (pro) |
| **Reasoning Effort** | minimal → high |
| **Verbosity** | low / medium / high |
| **API** | Responses API |

**Use Cases**:
- Daily GPT-5 usage
- Balanced cost/performance
- Moderate complexity tasks

#### GPT-5-nano
**Best for**: Ultra-fast GPT-5 queries

| Property | Value |
|----------|-------|
| **Pricing** | $0.05 input / $0.40 output + $0.40 reasoning per 1M tokens |
| **Vision** | ✅ Supported |
| **Max Tokens** | 16,384 (instant) → 128,000 (pro) |
| **Reasoning Effort** | minimal → high |
| **Verbosity** | low / medium / high |
| **API** | Responses API |

**Use Cases**:
- High-frequency queries
- Simple GPT-5-powered tasks
- Budget-sensitive applications

---

### 4. Image Generation - Creative AI

**Models**: DALL-E 2, DALL-E 3, gpt-image-1

**Characteristics**:
- Generate images from text prompts
- Size and quality control
- Safety filtering built-in
- Server-side storage

#### DALL-E 2
**Best for**: Fast, cost-effective images

| Property | Value |
|----------|-------|
| **Pricing** | $2.00 per image (1024x1024) |
| **Sizes Supported** | 256x256, 512x512, 1024x1024 |
| **Quality Options** | Standard only |
| **Response Format** | Base64 JSON |
| **API** | Images API |

**Use Cases**:
- Quick illustrations
- Icon generation
- Prototype designs

#### DALL-E 3
**Best for**: High-quality, detailed images

| Property | Value |
|----------|-------|
| **Pricing** | $4.00 (standard) / $8.00 (HD) per image |
| **Sizes Supported** | 1024x1024, 1024x1536, 1536x1024 |
| **Quality Options** | Standard, HD |
| **Response Format** | Base64 JSON |
| **Safety Filtering** | ✅ Automatic rewrites |
| **API** | Images API |

**Safety Features**:
- Automatic prompt rewrites for policy compliance
- Content filtering (violence, explicit content)
- Age-appropriate defaults

**Use Cases**:
- Marketing materials
- Educational visuals
- High-quality illustrations

#### gpt-image-1
**Best for**: Latest generation image model

| Property | Value |
|----------|-------|
| **Pricing** | $5.00 input / $40.00 output |
| **Sizes Supported** | Multiple (model-specific) |
| **Quality Options** | Model default |
| **Vision Input** | ✅ Supported |
| **API** | Images API |

**Use Cases**:
- Cutting-edge image generation
- Advanced creative tasks

---

## Mode System

Each model (except image generation) supports 4 runtime modes:

### Auto Mode (Default)
- **Purpose**: Balanced performance
- **Token Limit**: Medium
- **Temperature**: Standard model default
- **Use When**: General queries

### Instant Mode
- **Purpose**: Fast responses
- **Token Limit**: Reduced (~50% of auto)
- **Temperature**: Lower (more deterministic)
- **Use When**: Quick answers, simple queries

### Thinking Mode
- **Purpose**: Deep reasoning
- **Token Limit**: Increased (~150% of auto)
- **Temperature**: Slightly lower
- **Reasoning Effort**: High (for reasoning models)
- **Use When**: Complex problems, research

### Pro Mode
- **Purpose**: Maximum capabilities
- **Token Limit**: Maximum model allows
- **Temperature**: Very low (precise)
- **Reasoning Effort**: High
- **Use When**: Mission-critical tasks

---

## Cost Comparison Table

| Model Family | Cheapest Option | Most Powerful | Best Value |
|--------------|----------------|---------------|------------|
| **GPT-4** | GPT-4o-mini ($0.15/$0.60) | GPT-4.1 ($2.50/$10) | GPT-4o-mini |
| **o-Series** | o1-mini ($3/$12) | o3 ($20/$80) | o3-mini ($3.50/$14) |
| **GPT-5** | GPT-5-nano ($0.05/$0.40) | GPT-5 ($1.25/$10) | GPT-5-mini ($0.25/$2) |
| **Image** | DALL-E 2 ($2/img) | DALL-E 3 HD ($8/img) | DALL-E 2 |

---

## Model Selection Guide

### For Students

**Daily Q&A**: GPT-4o-mini (instant mode)
**Homework Help**: GPT-4o (auto mode)
**Complex Projects**: o1-mini or GPT-5-mini (thinking mode)
**Images**: DALL-E 2 or DALL-E 3 standard

### For Staff

**Quick Answers**: GPT-4o-mini (instant)
**Lesson Planning**: GPT-4o (auto)
**Research**: GPT-5 or o3-mini (thinking/pro)
**Presentations**: DALL-E 3 HD

### For Admins

**Cost Control**: Default to GPT-4o-mini, allow GPT-4o/GPT-5 on request
**Rate Limits**: Set daily limits on expensive models (o3, GPT-5)
**Monitoring**: Track usage patterns to optimize model recommendations

---

## Implementation Code

**From `/src/lib/config.ts`:**

```typescript
export const MODEL_CATALOG: Record<string, ModelMetadata> = {
  "gpt-4o-mini": {
    id: "gpt-4o-mini",
    label: "GPT-4o mini",
    description: "Fastest, most cost-effective",
    kind: "chat",
    family: "gpt-4",
    pricing: { input: 0.15, output: 0.60 },
    supports: { visionInput: true },
    modes: {
      auto: { temperature: 0.7, maxOutputTokens: 2048 },
      instant: { temperature: 0.4, maxOutputTokens: 1024 },
      thinking: { temperature: 0.6, maxOutputTokens: 4096 },
      pro: { temperature: 0.3, maxOutputTokens: 4096 },
    },
  },
  // ... 12 more models
};
```

**Model Selection in Chat API:**

```typescript
const ALLOWED_MODELS = getAllowedModels(); // From env or config
const model = requestedModel && ALLOWED_MODELS.includes(requestedModel) 
  ? requestedModel 
  : DEFAULT_MODEL;

const tuning = getModeTuning(model, mode); // Get mode-specific settings
```

---

## Future Considerations

**Potential Additions**:
- Claude models (Anthropic API)
- Gemini models (Google API)
- Local open-source models (Llama, Mistral)

**Model Deprecation Strategy**:
- Phase out models when OpenAI announces EOL
- Migrate users to equivalent newer models
- Maintain backward compatibility for 90 days

---

**See Also**:
- [API Architecture](04-api-architecture.md) - How different APIs are handled
- [Cost Analysis](08-cost-analysis.md) - Detailed pricing breakdown
- [Code Examples](../code-examples/) - Implementation samples
